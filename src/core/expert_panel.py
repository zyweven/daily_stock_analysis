# -*- coding: utf-8 -*-
"""
å¤šæ¨¡å‹ä¸“å®¶ä¼šè¯Šç®¡ç†å™¨ (Expert Panel Manager)

æ”¯æŒåŒæ—¶è°ƒç”¨å¤šä¸ª AI æ¨¡å‹å¯¹åŒä¸€åªè‚¡ç¥¨è¿›è¡Œç‹¬ç«‹åˆ†æï¼Œ
å¹¶æ±‡æ€»å„æ¨¡å‹è§‚ç‚¹ç”Ÿæˆ"ä¸“å®¶ä¼šè¯Š"æŠ¥å‘Šã€‚

ç‰¹æ€§ï¼š
- æ”¯æŒæœ€å¤š 5 ä¸ªæ¨¡å‹å¹¶è¡Œåˆ†æ
- è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”æ±‡æ€»å’Œç»¼åˆç»“è®º
- ä»…åœ¨ç”¨æˆ·æ‰‹åŠ¨è§¦å‘æ—¶æ‰§è¡Œï¼ˆå®šæ—¶ä»»åŠ¡ä¸æ”¯æŒï¼‰
"""

from __future__ import annotations

import json
import logging
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import dataclass
from typing import Any, Dict, List, Optional

from src.config import get_config

logger = logging.getLogger(__name__)

# æœ€å¤§å¹¶è¡Œæ¨¡å‹æ•°é‡
MAX_MODELS = 10


@dataclass
class ModelConfig:
    """å•ä¸ªæ¨¡å‹çš„é…ç½®ä¿¡æ¯"""
    name: str           # æ˜¾ç¤ºåç§° (å¦‚ "Gemini", "DeepSeek")
    provider: str       # æä¾›æ–¹ç±»å‹: "gemini" æˆ– "openai"
    api_key: str
    base_url: Optional[str] = None
    model_name: Optional[str] = None
    temperature: float = 0.7
    verify_ssl: bool = True


@dataclass
class ModelResult:
    """å•ä¸ªæ¨¡å‹çš„åˆ†æç»“æœ"""
    model_name: str
    success: bool
    score: Optional[int] = None
    advice: Optional[str] = None
    trend: Optional[str] = None
    summary: Optional[str] = None
    confidence: Optional[str] = None
    raw_result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    elapsed_seconds: float = 0.0

    def to_dict(self) -> Dict[str, Any]:
        return {
            "model_name": self.model_name,
            "success": self.success,
            "score": self.score,
            "advice": self.advice,
            "trend": self.trend,
            "summary": self.summary,
            "confidence": self.confidence,
            "elapsed_seconds": round(self.elapsed_seconds, 2),
            "error": self.error,
        }


@dataclass
class ExpertPanelResult:
    """ä¸“å®¶ä¼šè¯Šæ±‡æ€»ç»“æœ"""
    stock_code: str
    stock_name: str
    models_used: List[str]
    model_results: List[ModelResult]
    consensus_score: Optional[int] = None
    consensus_advice: Optional[str] = None
    consensus_summary: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        return {
            "stock_code": self.stock_code,
            "stock_name": self.stock_name,
            "models_used": self.models_used,
            "consensus_score": self.consensus_score,
            "consensus_advice": self.consensus_advice,
            "consensus_summary": self.consensus_summary,
            "model_results": [r.to_dict() for r in self.model_results],
        }

    def to_json(self) -> str:
        return json.dumps(self.to_dict(), ensure_ascii=False)


def parse_model_configs() -> List[ModelConfig]:
    """
    è§£ææ‰€æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®ã€‚
    æ”¯æŒé¡ºåºï¼š
    1. Gemini (ä¸»é…ç½®)
    2. OpenAI (ä¸»é…ç½®)
    3. EXTRA_AI_MODELS (JSON æ‰¹é‡é…ç½®)
    4. MODEL_N_... (å‘½åé…ç½®ï¼Œæ”¯æŒ 1-10)
    """
    import os
    configs: List[ModelConfig] = []
    config = get_config()

    # 1. Gemini
    gemini_key = config.gemini_api_key
    if gemini_key and not gemini_key.startswith("your_") and len(gemini_key) > 10:
        configs.append(ModelConfig(
            name="Gemini",
            provider="gemini",
            api_key=gemini_key,
            model_name=config.gemini_model,
            temperature=config.gemini_temperature,
        ))

    # 2. OpenAI (å®˜æ–¹æˆ–å…¼å®¹)
    openai_key = config.openai_api_key
    if openai_key and not openai_key.startswith("your_") and len(openai_key) > 10:
        display_name = "OpenAI"
        if config.openai_base_url and "deepseek" in config.openai_base_url.lower():
            display_name = "DeepSeek"
        elif config.openai_base_url and "openai" not in config.openai_base_url.lower():
            display_name = config.openai_model or "OpenAI-Compatible"
        configs.append(ModelConfig(
            name=display_name,
            provider="openai",
            api_key=openai_key,
            base_url=config.openai_base_url,
            model_name=config.openai_model,
            temperature=config.openai_temperature,
            verify_ssl=config.openai_verify_ssl,
        ))

    # 3. EXTRA_AI_MODELS (JSON æ‰¹é‡)
    if config.extra_ai_models:
        try:
            extra_list = json.loads(config.extra_ai_models)
            if isinstance(extra_list, list):
                for item in extra_list:
                    if isinstance(item, dict) and item.get("api_key"):
                        configs.append(ModelConfig(
                            name=item.get("name", item.get("model", "Extra-Model")),
                            provider=item.get("provider", "openai"),
                            api_key=item.get("api_key"),
                            base_url=item.get("base_url"),
                            model_name=item.get("model"),
                            temperature=float(item.get("temperature", 0.7)),
                            verify_ssl=item.get("verify_ssl", True) if isinstance(item.get("verify_ssl"), bool) else True,
                        ))
        except Exception as e:
            logger.warning(f"è§£æ EXTRA_AI_MODELS å¤±è´¥: {e}")

    # 4. MODEL_N_... (æ”¯æŒ 1-10)
    # æ’é™¤å·²ç»æ·»åŠ è¿‡çš„ï¼ˆé€šè¿‡ API Key ç®€å•åˆ¤é‡ï¼‰
    existing_keys = {c.api_key for c in configs}

    for i in range(1, 11):
        key = os.getenv(f"MODEL_{i}_API_KEY", "").strip()
        if key and not key.startswith("your_") and len(key) > 10 and key not in existing_keys:
            configs.append(ModelConfig(
                name=os.getenv(f"MODEL_{i}_DISPLAY_NAME", f"Model-{i}"),
                provider=os.getenv(f"MODEL_{i}_PROVIDER", "openai"),
                api_key=key,
                base_url=os.getenv(f"MODEL_{i}_BASE_URL"),
                model_name=os.getenv(f"MODEL_{i}_NAME", "gpt-4o-mini"),
                temperature=float(os.getenv(f"MODEL_{i}_TEMPERATURE", "0.7")),
            ))
            existing_keys.add(key)

    return configs[:MAX_MODELS]


def _run_single_model(
    model_config: ModelConfig,
    context: Dict[str, Any],
    news_context: Optional[str],
) -> ModelResult:
    """
    ä½¿ç”¨å•ä¸ªæ¨¡å‹æ‰§è¡Œåˆ†æã€‚
    """
    start = time.time()
    try:
        from src.analyzer import GeminiAnalyzer
        
        # æ„é€ æ˜¾å¼æ¨¡å‹å‚æ•°
        params = {
            "name": model_config.name,
            "provider": model_config.provider,
            "api_key": model_config.api_key,
            "base_url": model_config.base_url,
            "model": model_config.model_name,
            "temperature": model_config.temperature,
            "verify_ssl": model_config.verify_ssl,
        }
        
        # åˆ›å»ºåˆ†æå™¨å®ä¾‹ï¼Œä¼ å…¥æ˜¾å¼å‚æ•°
        # è¿™æ ·æ— éœ€ç¯å¢ƒå˜é‡åˆ‡æ¢ï¼Œæ”¯æŒçœŸæ­£çš„å¹¶è¡Œ
        analyzer = GeminiAnalyzer(model_params=params)

        if not analyzer.is_available():
            return ModelResult(
                model_name=model_config.name,
                success=False,
                error="åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥æˆ– API Key æ— æ•ˆ",
            )

        result = analyzer.analyze(context, news_context)
        elapsed = time.time() - start

        return ModelResult(
            model_name=model_config.name,
            success=result.success if hasattr(result, 'success') else True,
            score=result.sentiment_score,
            advice=result.operation_advice,
            trend=result.trend_prediction,
            summary=result.analysis_summary,
            confidence=result.confidence_level if hasattr(result, 'confidence_level') else None,
            raw_result=result.to_dict() if hasattr(result, 'to_dict') else None,
            elapsed_seconds=elapsed,
        )

    except Exception as e:
        elapsed = time.time() - start
        logger.error(f"[ä¸“å®¶ä¼šè¯Š] {model_config.name} åˆ†æå¤±è´¥: {e}")
        return ModelResult(
            model_name=model_config.name,
            success=False,
            error=str(e)[:200],
            elapsed_seconds=elapsed,
        )




def _compute_consensus(results: List[ModelResult]) -> Dict[str, Any]:
    """
    è®¡ç®—å¤šæ¨¡å‹å…±è¯†ç»“è®ºã€‚

    ç®—æ³•ï¼š
    1. è¯„åˆ†ï¼šå–æˆåŠŸæ¨¡å‹è¯„åˆ†çš„å¹³å‡å€¼
    2. å»ºè®®ï¼šå¤šæ•°ç¥¨åˆ¶ï¼ˆå‡ºç°æ¬¡æ•°æœ€å¤šçš„å»ºè®®ï¼‰
    3. æ‘˜è¦ï¼šæ±‡æ€»å„æ¨¡å‹è§‚ç‚¹
    """
    successful = [r for r in results if r.success and r.score is not None]
    if not successful:
        return {
            "score": None,
            "advice": "æ•°æ®ä¸è¶³",
            "summary": "æ‰€æœ‰æ¨¡å‹åˆ†æå‡å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå…±è¯†ç»“è®ºã€‚",
        }

    # å¹³å‡è¯„åˆ†
    avg_score = round(sum(r.score for r in successful) / len(successful))

    # å»ºè®®æŠ•ç¥¨
    advice_counts: Dict[str, int] = {}
    for r in successful:
        if r.advice:
            advice_counts[r.advice] = advice_counts.get(r.advice, 0) + 1
    top_advice = max(advice_counts, key=advice_counts.get) if advice_counts else "è§‚æœ›"

    # ç”Ÿæˆå…±è¯†æ‘˜è¦
    agree_count = advice_counts.get(top_advice, 0)
    total = len(successful)
    if agree_count == total:
        consensus_text = f"å…¨éƒ¨ {total} ä½ä¸“å®¶ä¸€è‡´å»ºè®®ã€{top_advice}ã€‘"
    else:
        consensus_text = f"{agree_count}/{total} ä½ä¸“å®¶å»ºè®®ã€{top_advice}ã€‘"
        dissenting = [r for r in successful if r.advice != top_advice]
        if dissenting:
            alt_views = ", ".join(f"{r.model_name}å»ºè®®{r.advice}" for r in dissenting)
            consensus_text += f"ï¼Œä½† {alt_views}"

    # è¯„åˆ†åŒºé—´æè¿°
    scores = [r.score for r in successful]
    score_range = f"è¯„åˆ†åŒºé—´: {min(scores)}-{max(scores)}, å‡å€¼: {avg_score}"

    summary = f"ğŸ“Š {consensus_text}ã€‚{score_range}ã€‚"

    return {
        "score": avg_score,
        "advice": top_advice,
        "summary": summary,
    }


def run_expert_panel(
    context: Dict[str, Any],
    news_context: Optional[str] = None,
    selected_models: Optional[List[str]] = None,
    max_workers: int = 3,
) -> ExpertPanelResult:
    """
    æ‰§è¡Œä¸“å®¶ä¼šè¯Šåˆ†æã€‚

    Args:
        context: è‚¡ç¥¨åˆ†æä¸Šä¸‹æ–‡
        news_context: æ–°é—»å†…å®¹
        selected_models: ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹åç§°åˆ—è¡¨ï¼ˆå¦‚ ["Gemini", "DeepSeek"]ï¼‰
        max_workers: æœ€å¤§å¹¶è¡Œçº¿ç¨‹æ•°

    Returns:
        ExpertPanelResult æ±‡æ€»ç»“æœ
    """
    stock_code = context.get("code", "Unknown")
    stock_name = context.get("stock_name", stock_code)

    # è·å–æ‰€æœ‰å¯ç”¨æ¨¡å‹
    all_configs = parse_model_configs()
    if not all_configs:
        return ExpertPanelResult(
            stock_code=stock_code,
            stock_name=stock_name,
            models_used=[],
            model_results=[],
            consensus_summary="æœªé…ç½®ä»»ä½• AI æ¨¡å‹ï¼Œæ— æ³•æ‰§è¡Œä¸“å®¶ä¼šè¯Šã€‚",
        )

    # å¦‚æœç”¨æˆ·æŒ‡å®šäº†æ¨¡å‹åˆ—è¡¨ï¼Œåˆ™è¿‡æ»¤
    if selected_models:
        selected_lower = [m.lower() for m in selected_models]
        configs = [c for c in all_configs if c.name.lower() in selected_lower]
        if not configs:
            configs = all_configs  # åŒ¹é…å¤±è´¥ï¼Œä½¿ç”¨å…¨éƒ¨
    else:
        configs = all_configs

    configs = configs[:MAX_MODELS]
    model_names = [c.name for c in configs]

    logger.info(f"[ä¸“å®¶ä¼šè¯Š] å¼€å§‹åˆ†æ {stock_name}({stock_code}), æ¨¡å‹: {model_names}")

    # å¹¶è¡Œæ‰§è¡Œ
    model_results: List[ModelResult] = []
    with ThreadPoolExecutor(max_workers=min(max_workers, len(configs))) as executor:
        future_to_model = {
            executor.submit(_run_single_model, cfg, context, news_context): cfg.name
            for cfg in configs
        }
        for future in as_completed(future_to_model):
            model_name = future_to_model[future]
            try:
                result = future.result(timeout=300)
                model_results.append(result)
                status = "âœ…" if result.success else "âŒ"
                logger.info(f"[ä¸“å®¶ä¼šè¯Š] {status} {model_name}: score={result.score}, advice={result.advice}")
            except Exception as e:
                logger.error(f"[ä¸“å®¶ä¼šè¯Š] {model_name} å¼‚å¸¸: {e}")
                model_results.append(ModelResult(
                    model_name=model_name,
                    success=False,
                    error=str(e)[:200],
                ))

    # æŒ‰æ¨¡å‹åç§°æ’åºï¼ˆä¿æŒä¸€è‡´çš„å±•ç¤ºé¡ºåºï¼‰
    model_results.sort(key=lambda r: model_names.index(r.model_name) if r.model_name in model_names else 999)

    # è®¡ç®—å…±è¯†
    consensus = _compute_consensus(model_results)

    panel_result = ExpertPanelResult(
        stock_code=stock_code,
        stock_name=stock_name,
        models_used=model_names,
        model_results=model_results,
        consensus_score=consensus["score"],
        consensus_advice=consensus["advice"],
        consensus_summary=consensus["summary"],
    )

    logger.info(f"[ä¸“å®¶ä¼šè¯Š] åˆ†æå®Œæˆ: {consensus['summary']}")
    return panel_result
