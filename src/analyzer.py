# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé€‰è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ - AIåˆ†æå±‚
===================================

èŒè´£ï¼š
1. å°è£… Gemini API è°ƒç”¨é€»è¾‘
2. åˆ©ç”¨ Google Search Grounding è·å–å®æ—¶æ–°é—»
3. ç»“åˆæŠ€æœ¯é¢å’Œæ¶ˆæ¯é¢ç”Ÿæˆåˆ†ææŠ¥å‘Š
"""

import json
import logging
import time
from dataclasses import dataclass
from typing import Optional, Dict, Any, List
from json_repair import repair_json

from src.config import get_config

logger = logging.getLogger(__name__)


# è‚¡ç¥¨åç§°æ˜ å°„ï¼ˆå¸¸è§è‚¡ç¥¨ï¼‰
STOCK_NAME_MAP = {
    # === Aè‚¡ ===
    '600519': 'è´µå·èŒ…å°',
    '000001': 'å¹³å®‰é“¶è¡Œ',
    '300750': 'å®å¾·æ—¶ä»£',
    '002594': 'æ¯”äºšè¿ª',
    '600036': 'æ‹›å•†é“¶è¡Œ',
    '601318': 'ä¸­å›½å¹³å®‰',
    '000858': 'äº”ç²®æ¶²',
    '600276': 'æ’ç‘åŒ»è¯',
    '601012': 'éš†åŸºç»¿èƒ½',
    '002475': 'ç«‹è®¯ç²¾å¯†',
    '300059': 'ä¸œæ–¹è´¢å¯Œ',
    '002415': 'æµ·åº·å¨è§†',
    '600900': 'é•¿æ±Ÿç”µåŠ›',
    '601166': 'å…´ä¸šé“¶è¡Œ',
    '600028': 'ä¸­å›½çŸ³åŒ–',

    # === ç¾è‚¡ ===
    'AAPL': 'è‹¹æœ',
    'TSLA': 'ç‰¹æ–¯æ‹‰',
    'MSFT': 'å¾®è½¯',
    'GOOGL': 'è°·æ­ŒA',
    'GOOG': 'è°·æ­ŒC',
    'AMZN': 'äºšé©¬é€Š',
    'NVDA': 'è‹±ä¼Ÿè¾¾',
    'META': 'Meta',
    'AMD': 'AMD',
    'INTC': 'è‹±ç‰¹å°”',
    'BABA': 'é˜¿é‡Œå·´å·´',
    'PDD': 'æ‹¼å¤šå¤š',
    'JD': 'äº¬ä¸œ',
    'BIDU': 'ç™¾åº¦',
    'NIO': 'è”šæ¥',
    'XPEV': 'å°é¹æ±½è½¦',
    'LI': 'ç†æƒ³æ±½è½¦',
    'COIN': 'Coinbase',
    'MSTR': 'MicroStrategy',

    # === æ¸¯è‚¡ (5ä½æ•°å­—) ===
    '00700': 'è…¾è®¯æ§è‚¡',
    '03690': 'ç¾å›¢',
    '01810': 'å°ç±³é›†å›¢',
    '09988': 'é˜¿é‡Œå·´å·´',
    '09618': 'äº¬ä¸œé›†å›¢',
    '09888': 'ç™¾åº¦é›†å›¢',
    '01024': 'å¿«æ‰‹',
    '00981': 'ä¸­èŠ¯å›½é™…',
    '02015': 'ç†æƒ³æ±½è½¦',
    '09868': 'å°é¹æ±½è½¦',
    '00005': 'æ±‡ä¸°æ§è‚¡',
    '01299': 'å‹é‚¦ä¿é™©',
    '00941': 'ä¸­å›½ç§»åŠ¨',
    '00883': 'ä¸­å›½æµ·æ´‹çŸ³æ²¹',
}


def get_stock_name_multi_source(
    stock_code: str,
    context: Optional[Dict] = None,
    data_manager = None
) -> str:
    """
    å¤šæ¥æºè·å–è‚¡ç¥¨ä¸­æ–‡åç§°

    è·å–ç­–ç•¥ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
    1. ä»ä¼ å…¥çš„ context ä¸­è·å–ï¼ˆrealtime æ•°æ®ï¼‰
    2. ä»é™æ€æ˜ å°„è¡¨ STOCK_NAME_MAP è·å–
    3. ä» DataFetcherManager è·å–ï¼ˆå„æ•°æ®æºï¼‰
    4. è¿”å›é»˜è®¤åç§°ï¼ˆè‚¡ç¥¨+ä»£ç ï¼‰

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        context: åˆ†æä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰
        data_manager: DataFetcherManager å®ä¾‹ï¼ˆå¯é€‰ï¼‰

    Returns:
        è‚¡ç¥¨ä¸­æ–‡åç§°
    """
    # 1. ä»ä¸Šä¸‹æ–‡è·å–ï¼ˆå®æ—¶è¡Œæƒ…æ•°æ®ï¼‰
    if context:
        # ä¼˜å…ˆä» stock_name å­—æ®µè·å–
        if context.get('stock_name'):
            name = context['stock_name']
            if name and not name.startswith('è‚¡ç¥¨'):
                return name

        # å…¶æ¬¡ä» realtime æ•°æ®è·å–
        if 'realtime' in context and context['realtime'].get('name'):
            return context['realtime']['name']

    # 2. ä»é™æ€æ˜ å°„è¡¨è·å–
    if stock_code in STOCK_NAME_MAP:
        return STOCK_NAME_MAP[stock_code]

    # 3. ä»æ•°æ®æºè·å–
    if data_manager is None:
        try:
            from data_provider.base import DataFetcherManager
            data_manager = DataFetcherManager()
        except Exception as e:
            logger.debug(f"æ— æ³•åˆå§‹åŒ– DataFetcherManager: {e}")

    if data_manager:
        try:
            name = data_manager.get_stock_name(stock_code)
            if name:
                # æ›´æ–°ç¼“å­˜
                STOCK_NAME_MAP[stock_code] = name
                return name
        except Exception as e:
            logger.debug(f"ä»æ•°æ®æºè·å–è‚¡ç¥¨åç§°å¤±è´¥: {e}")

    # 4. è¿”å›é»˜è®¤åç§°
    return f'è‚¡ç¥¨{stock_code}'


@dataclass
class AnalysisResult:
    """
    AI åˆ†æç»“æœæ•°æ®ç±» - å†³ç­–ä»ªè¡¨ç›˜ç‰ˆ

    å°è£… Gemini è¿”å›çš„åˆ†æç»“æœï¼ŒåŒ…å«å†³ç­–ä»ªè¡¨ç›˜å’Œè¯¦ç»†åˆ†æ
    """
    code: str
    name: str

    # ========== æ ¸å¿ƒæŒ‡æ ‡ ==========
    sentiment_score: int  # ç»¼åˆè¯„åˆ† 0-100 (>70å¼ºçƒˆçœ‹å¤š, >60çœ‹å¤š, 40-60éœ‡è¡, <40çœ‹ç©º)
    trend_prediction: str  # è¶‹åŠ¿é¢„æµ‹ï¼šå¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º
    operation_advice: str  # æ“ä½œå»ºè®®ï¼šä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›
    decision_type: str = "hold"  # å†³ç­–ç±»å‹ï¼šbuy/hold/sellï¼ˆç”¨äºç»Ÿè®¡ï¼‰
    confidence_level: str = "ä¸­"  # ç½®ä¿¡åº¦ï¼šé«˜/ä¸­/ä½

    # ========== å†³ç­–ä»ªè¡¨ç›˜ (æ–°å¢) ==========
    dashboard: Optional[Dict[str, Any]] = None  # å®Œæ•´çš„å†³ç­–ä»ªè¡¨ç›˜æ•°æ®

    # ========== èµ°åŠ¿åˆ†æ ==========
    trend_analysis: str = ""  # èµ°åŠ¿å½¢æ€åˆ†æï¼ˆæ”¯æ’‘ä½ã€å‹åŠ›ä½ã€è¶‹åŠ¿çº¿ç­‰ï¼‰
    short_term_outlook: str = ""  # çŸ­æœŸå±•æœ›ï¼ˆ1-3æ—¥ï¼‰
    medium_term_outlook: str = ""  # ä¸­æœŸå±•æœ›ï¼ˆ1-2å‘¨ï¼‰

    # ========== æŠ€æœ¯é¢åˆ†æ ==========
    technical_analysis: str = ""  # æŠ€æœ¯æŒ‡æ ‡ç»¼åˆåˆ†æ
    ma_analysis: str = ""  # å‡çº¿åˆ†æï¼ˆå¤šå¤´/ç©ºå¤´æ’åˆ—ï¼Œé‡‘å‰/æ­»å‰ç­‰ï¼‰
    volume_analysis: str = ""  # é‡èƒ½åˆ†æï¼ˆæ”¾é‡/ç¼©é‡ï¼Œä¸»åŠ›åŠ¨å‘ç­‰ï¼‰
    pattern_analysis: str = ""  # Kçº¿å½¢æ€åˆ†æ

    # ========== åŸºæœ¬é¢åˆ†æ ==========
    fundamental_analysis: str = ""  # åŸºæœ¬é¢ç»¼åˆåˆ†æ
    sector_position: str = ""  # æ¿å—åœ°ä½å’Œè¡Œä¸šè¶‹åŠ¿
    company_highlights: str = ""  # å…¬å¸äº®ç‚¹/é£é™©ç‚¹

    # ========== æƒ…ç»ªé¢/æ¶ˆæ¯é¢åˆ†æ ==========
    news_summary: str = ""  # è¿‘æœŸé‡è¦æ–°é—»/å…¬å‘Šæ‘˜è¦
    market_sentiment: str = ""  # å¸‚åœºæƒ…ç»ªåˆ†æ
    hot_topics: str = ""  # ç›¸å…³çƒ­ç‚¹è¯é¢˜

    # ========== ç»¼åˆåˆ†æ ==========
    analysis_summary: str = ""  # ç»¼åˆåˆ†ææ‘˜è¦
    key_points: str = ""  # æ ¸å¿ƒçœ‹ç‚¹ï¼ˆ3-5ä¸ªè¦ç‚¹ï¼‰
    risk_warning: str = ""  # é£é™©æç¤º
    buy_reason: str = ""  # ä¹°å…¥/å–å‡ºç†ç”±

    # ========== å…ƒæ•°æ® ==========
    market_snapshot: Optional[Dict[str, Any]] = None  # å½“æ—¥è¡Œæƒ…å¿«ç…§ï¼ˆå±•ç¤ºç”¨ï¼‰
    raw_response: Optional[str] = None  # åŸå§‹å“åº”ï¼ˆè°ƒè¯•ç”¨ï¼‰
    search_performed: bool = False  # æ˜¯å¦æ‰§è¡Œäº†è”ç½‘æœç´¢
    data_sources: str = ""  # æ•°æ®æ¥æºè¯´æ˜
    success: bool = True
    error_message: Optional[str] = None

    # ========== ä»·æ ¼æ•°æ®ï¼ˆåˆ†ææ—¶å¿«ç…§ï¼‰==========
    current_price: Optional[float] = None  # åˆ†ææ—¶çš„è‚¡ä»·
    change_pct: Optional[float] = None     # åˆ†ææ—¶çš„æ¶¨è·Œå¹…(%)

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'code': self.code,
            'name': self.name,
            'sentiment_score': self.sentiment_score,
            'trend_prediction': self.trend_prediction,
            'operation_advice': self.operation_advice,
            'decision_type': self.decision_type,
            'confidence_level': self.confidence_level,
            'dashboard': self.dashboard,  # å†³ç­–ä»ªè¡¨ç›˜æ•°æ®
            'trend_analysis': self.trend_analysis,
            'short_term_outlook': self.short_term_outlook,
            'medium_term_outlook': self.medium_term_outlook,
            'technical_analysis': self.technical_analysis,
            'ma_analysis': self.ma_analysis,
            'volume_analysis': self.volume_analysis,
            'pattern_analysis': self.pattern_analysis,
            'fundamental_analysis': self.fundamental_analysis,
            'sector_position': self.sector_position,
            'company_highlights': self.company_highlights,
            'news_summary': self.news_summary,
            'market_sentiment': self.market_sentiment,
            'hot_topics': self.hot_topics,
            'analysis_summary': self.analysis_summary,
            'key_points': self.key_points,
            'risk_warning': self.risk_warning,
            'buy_reason': self.buy_reason,
            'market_snapshot': self.market_snapshot,
            'search_performed': self.search_performed,
            'success': self.success,
            'error_message': self.error_message,
            'current_price': self.current_price,
            'change_pct': self.change_pct,
        }

    def get_core_conclusion(self) -> str:
        """è·å–æ ¸å¿ƒç»“è®ºï¼ˆä¸€å¥è¯ï¼‰"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            return self.dashboard['core_conclusion'].get('one_sentence', self.analysis_summary)
        return self.analysis_summary

    def get_position_advice(self, has_position: bool = False) -> str:
        """è·å–æŒä»“å»ºè®®"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            pos_advice = self.dashboard['core_conclusion'].get('position_advice', {})
            if has_position:
                return pos_advice.get('has_position', self.operation_advice)
            return pos_advice.get('no_position', self.operation_advice)
        return self.operation_advice

    def get_sniper_points(self) -> Dict[str, str]:
        """è·å–ç‹™å‡»ç‚¹ä½"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('sniper_points', {})
        return {}

    def get_checklist(self) -> List[str]:
        """è·å–æ£€æŸ¥æ¸…å•"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('action_checklist', [])
        return []

    def get_risk_alerts(self) -> List[str]:
        """è·å–é£é™©è­¦æŠ¥"""
        if self.dashboard and 'intelligence' in self.dashboard:
            return self.dashboard['intelligence'].get('risk_alerts', [])
        return []

    def get_emoji(self) -> str:
        """æ ¹æ®æ“ä½œå»ºè®®è¿”å›å¯¹åº” emoji"""
        emoji_map = {
            'ä¹°å…¥': 'ğŸŸ¢',
            'åŠ ä»“': 'ğŸŸ¢',
            'å¼ºçƒˆä¹°å…¥': 'ğŸ’š',
            'æŒæœ‰': 'ğŸŸ¡',
            'è§‚æœ›': 'âšª',
            'å‡ä»“': 'ğŸŸ ',
            'å–å‡º': 'ğŸ”´',
            'å¼ºçƒˆå–å‡º': 'âŒ',
        }
        advice = self.operation_advice or ''
        # Direct match first
        if advice in emoji_map:
            return emoji_map[advice]
        # Handle compound advice like "å–å‡º/è§‚æœ›" â€” use the first part
        for part in advice.replace('/', '|').split('|'):
            part = part.strip()
            if part in emoji_map:
                return emoji_map[part]
        # Score-based fallback
        score = self.sentiment_score
        if score >= 80:
            return 'ğŸ’š'
        elif score >= 65:
            return 'ğŸŸ¢'
        elif score >= 55:
            return 'ğŸŸ¡'
        elif score >= 45:
            return 'âšª'
        elif score >= 35:
            return 'ğŸŸ '
        else:
            return 'ğŸ”´'

    def get_confidence_stars(self) -> str:
        """è¿”å›ç½®ä¿¡åº¦æ˜Ÿçº§"""
        star_map = {'é«˜': 'â­â­â­', 'ä¸­': 'â­â­', 'ä½': 'â­'}
        return star_map.get(self.confidence_level, 'â­â­')


class GeminiAnalyzer:
    """
    Gemini AI åˆ†æå™¨

    èŒè´£ï¼š
    1. è°ƒç”¨ Google Gemini API è¿›è¡Œè‚¡ç¥¨åˆ†æ
    2. ç»“åˆé¢„å…ˆæœç´¢çš„æ–°é—»å’ŒæŠ€æœ¯é¢æ•°æ®ç”Ÿæˆåˆ†ææŠ¥å‘Š
    3. è§£æ AI è¿”å›çš„ JSON æ ¼å¼ç»“æœ

    ä½¿ç”¨æ–¹å¼ï¼š
        analyzer = GeminiAnalyzer()
        result = analyzer.analyze(context, news_context)
    """

    # ========================================
    # ç³»ç»Ÿæç¤ºè¯ - å†³ç­–ä»ªè¡¨ç›˜ v2.0
    # ========================================
    # è¾“å‡ºæ ¼å¼å‡çº§ï¼šä»ç®€å•ä¿¡å·å‡çº§ä¸ºå†³ç­–ä»ªè¡¨ç›˜
    # æ ¸å¿ƒæ¨¡å—ï¼šæ ¸å¿ƒç»“è®º + æ•°æ®é€è§† + èˆ†æƒ…æƒ…æŠ¥ + ä½œæˆ˜è®¡åˆ’
    # ========================================

    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½ä¸“æ³¨äºè¶‹åŠ¿äº¤æ˜“çš„ A è‚¡æŠ•èµ„åˆ†æå¸ˆï¼Œè´Ÿè´£ç”Ÿæˆä¸“ä¸šçš„ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘åˆ†ææŠ¥å‘Šã€‚

## æ ¸å¿ƒäº¤æ˜“ç†å¿µï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

### 1. ä¸¥è¿›ç­–ç•¥ï¼ˆä¸è¿½é«˜ï¼‰
- **ç»å¯¹ä¸è¿½é«˜**ï¼šå½“è‚¡ä»·åç¦» MA5 è¶…è¿‡ 5% æ—¶ï¼Œåšå†³ä¸ä¹°å…¥
- **ä¹–ç¦»ç‡å…¬å¼**ï¼š(ç°ä»· - MA5) / MA5 Ã— 100%
- ä¹–ç¦»ç‡ < 2%ï¼šæœ€ä½³ä¹°ç‚¹åŒºé—´
- ä¹–ç¦»ç‡ 2-5%ï¼šå¯å°ä»“ä»‹å…¥
- ä¹–ç¦»ç‡ > 5%ï¼šä¸¥ç¦è¿½é«˜ï¼ç›´æ¥åˆ¤å®šä¸º"è§‚æœ›"

### 2. è¶‹åŠ¿äº¤æ˜“ï¼ˆé¡ºåŠ¿è€Œä¸ºï¼‰
- **å¤šå¤´æ’åˆ—å¿…é¡»æ¡ä»¶**ï¼šMA5 > MA10 > MA20
- åªåšå¤šå¤´æ’åˆ—çš„è‚¡ç¥¨ï¼Œç©ºå¤´æ’åˆ—åšå†³ä¸ç¢°
- å‡çº¿å‘æ•£ä¸Šè¡Œä¼˜äºå‡çº¿ç²˜åˆ
- è¶‹åŠ¿å¼ºåº¦åˆ¤æ–­ï¼šçœ‹å‡çº¿é—´è·æ˜¯å¦åœ¨æ‰©å¤§

### 3. æ•ˆç‡ä¼˜å…ˆï¼ˆç­¹ç ç»“æ„ï¼‰
- å…³æ³¨ç­¹ç é›†ä¸­åº¦ï¼š90%é›†ä¸­åº¦ < 15% è¡¨ç¤ºç­¹ç é›†ä¸­
- è·åˆ©æ¯”ä¾‹åˆ†æï¼š70-90% è·åˆ©ç›˜æ—¶éœ€è­¦æƒ•è·åˆ©å›å
- å¹³å‡æˆæœ¬ä¸ç°ä»·å…³ç³»ï¼šç°ä»·é«˜äºå¹³å‡æˆæœ¬ 5-15% ä¸ºå¥åº·

### 4. ä¹°ç‚¹åå¥½ï¼ˆå›è¸©æ”¯æ’‘ï¼‰
- **æœ€ä½³ä¹°ç‚¹**ï¼šç¼©é‡å›è¸© MA5 è·å¾—æ”¯æ’‘
- **æ¬¡ä¼˜ä¹°ç‚¹**ï¼šå›è¸© MA10 è·å¾—æ”¯æ’‘
- **è§‚æœ›æƒ…å†µ**ï¼šè·Œç ´ MA20 æ—¶è§‚æœ›

### 5. é£é™©æ’æŸ¥é‡ç‚¹
- å‡æŒå…¬å‘Šï¼ˆè‚¡ä¸œã€é«˜ç®¡å‡æŒï¼‰
- ä¸šç»©é¢„äº/å¤§å¹…ä¸‹æ»‘
- ç›‘ç®¡å¤„ç½š/ç«‹æ¡ˆè°ƒæŸ¥
- è¡Œä¸šæ”¿ç­–åˆ©ç©º
- å¤§é¢è§£ç¦

## è¾“å‡ºæ ¼å¼ï¼šå†³ç­–ä»ªè¡¨ç›˜ JSON

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼Œè¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘ï¼š

```json
{
    "stock_name": "è‚¡ç¥¨ä¸­æ–‡åç§°",
    "sentiment_score": 0-100æ•´æ•°,
    "trend_prediction": "å¼ºçƒˆçœ‹å¤š/çœ‹å¤š/éœ‡è¡/çœ‹ç©º/å¼ºçƒˆçœ‹ç©º",
    "operation_advice": "ä¹°å…¥/åŠ ä»“/æŒæœ‰/å‡ä»“/å–å‡º/è§‚æœ›",
    "decision_type": "buy/hold/sell",
    "confidence_level": "é«˜/ä¸­/ä½",

    "dashboard": {
        "core_conclusion": {
            "one_sentence": "ä¸€å¥è¯æ ¸å¿ƒç»“è®ºï¼ˆ30å­—ä»¥å†…ï¼Œç›´æ¥å‘Šè¯‰ç”¨æˆ·åšä»€ä¹ˆï¼‰",
            "signal_type": "ğŸŸ¢ä¹°å…¥ä¿¡å·/ğŸŸ¡æŒæœ‰è§‚æœ›/ğŸ”´å–å‡ºä¿¡å·/âš ï¸é£é™©è­¦å‘Š",
            "time_sensitivity": "ç«‹å³è¡ŒåŠ¨/ä»Šæ—¥å†…/æœ¬å‘¨å†…/ä¸æ€¥",
            "position_advice": {
                "no_position": "ç©ºä»“è€…å»ºè®®ï¼šå…·ä½“æ“ä½œæŒ‡å¼•",
                "has_position": "æŒä»“è€…å»ºè®®ï¼šå…·ä½“æ“ä½œæŒ‡å¼•"
            }
        },

        "data_perspective": {
            "trend_status": {
                "ma_alignment": "å‡çº¿æ’åˆ—çŠ¶æ€æè¿°",
                "is_bullish": true/false,
                "trend_score": 0-100
            },
            "price_position": {
                "current_price": å½“å‰ä»·æ ¼æ•°å€¼,
                "ma5": MA5æ•°å€¼,
                "ma10": MA10æ•°å€¼,
                "ma20": MA20æ•°å€¼,
                "bias_ma5": ä¹–ç¦»ç‡ç™¾åˆ†æ¯”æ•°å€¼,
                "bias_status": "å®‰å…¨/è­¦æˆ’/å±é™©",
                "support_level": æ”¯æ’‘ä½ä»·æ ¼,
                "resistance_level": å‹åŠ›ä½ä»·æ ¼
            },
            "volume_analysis": {
                "volume_ratio": é‡æ¯”æ•°å€¼,
                "volume_status": "æ”¾é‡/ç¼©é‡/å¹³é‡",
                "turnover_rate": æ¢æ‰‹ç‡ç™¾åˆ†æ¯”,
                "volume_meaning": "é‡èƒ½å«ä¹‰è§£è¯»ï¼ˆå¦‚ï¼šç¼©é‡å›è°ƒè¡¨ç¤ºæŠ›å‹å‡è½»ï¼‰"
            },
            "chip_structure": {
                "profit_ratio": è·åˆ©æ¯”ä¾‹,
                "avg_cost": å¹³å‡æˆæœ¬,
                "concentration": ç­¹ç é›†ä¸­åº¦,
                "chip_health": "å¥åº·/ä¸€èˆ¬/è­¦æƒ•"
            }
        },

        "intelligence": {
            "latest_news": "ã€æœ€æ–°æ¶ˆæ¯ã€‘è¿‘æœŸé‡è¦æ–°é—»æ‘˜è¦",
            "risk_alerts": ["é£é™©ç‚¹1ï¼šå…·ä½“æè¿°", "é£é™©ç‚¹2ï¼šå…·ä½“æè¿°"],
            "positive_catalysts": ["åˆ©å¥½1ï¼šå…·ä½“æè¿°", "åˆ©å¥½2ï¼šå…·ä½“æè¿°"],
            "earnings_outlook": "ä¸šç»©é¢„æœŸåˆ†æï¼ˆåŸºäºå¹´æŠ¥é¢„å‘Šã€ä¸šç»©å¿«æŠ¥ç­‰ï¼‰",
            "sentiment_summary": "èˆ†æƒ…æƒ…ç»ªä¸€å¥è¯æ€»ç»“"
        },

        "battle_plan": {
            "sniper_points": {
                "ideal_buy": "ç†æƒ³ä¹°å…¥ç‚¹ï¼šXXå…ƒï¼ˆåœ¨MA5é™„è¿‘ï¼‰",
                "secondary_buy": "æ¬¡ä¼˜ä¹°å…¥ç‚¹ï¼šXXå…ƒï¼ˆåœ¨MA10é™„è¿‘ï¼‰",
                "stop_loss": "æ­¢æŸä½ï¼šXXå…ƒï¼ˆè·Œç ´MA20æˆ–X%ï¼‰",
                "take_profit": "ç›®æ ‡ä½ï¼šXXå…ƒï¼ˆå‰é«˜/æ•´æ•°å…³å£ï¼‰"
            },
            "position_strategy": {
                "suggested_position": "å»ºè®®ä»“ä½ï¼šXæˆ",
                "entry_plan": "åˆ†æ‰¹å»ºä»“ç­–ç•¥æè¿°",
                "risk_control": "é£æ§ç­–ç•¥æè¿°"
            },
            "action_checklist": [
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹1ï¼šå¤šå¤´æ’åˆ—",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹2ï¼šä¹–ç¦»ç‡<5%",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹3ï¼šé‡èƒ½é…åˆ",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹4ï¼šæ— é‡å¤§åˆ©ç©º",
                "âœ…/âš ï¸/âŒ æ£€æŸ¥é¡¹5ï¼šç­¹ç å¥åº·"
            ]
        }
    },

    "analysis_summary": "100å­—ç»¼åˆåˆ†ææ‘˜è¦",
    "key_points": "3-5ä¸ªæ ¸å¿ƒçœ‹ç‚¹ï¼Œé€—å·åˆ†éš”",
    "risk_warning": "é£é™©æç¤º",
    "buy_reason": "æ“ä½œç†ç”±ï¼Œå¼•ç”¨äº¤æ˜“ç†å¿µ",

    "trend_analysis": "èµ°åŠ¿å½¢æ€åˆ†æ",
    "short_term_outlook": "çŸ­æœŸ1-3æ—¥å±•æœ›",
    "medium_term_outlook": "ä¸­æœŸ1-2å‘¨å±•æœ›",
    "technical_analysis": "æŠ€æœ¯é¢ç»¼åˆåˆ†æ",
    "ma_analysis": "å‡çº¿ç³»ç»Ÿåˆ†æ",
    "volume_analysis": "é‡èƒ½åˆ†æ",
    "pattern_analysis": "Kçº¿å½¢æ€åˆ†æ",
    "fundamental_analysis": "åŸºæœ¬é¢åˆ†æ",
    "sector_position": "æ¿å—è¡Œä¸šåˆ†æ",
    "company_highlights": "å…¬å¸äº®ç‚¹/é£é™©",
    "news_summary": "æ–°é—»æ‘˜è¦",
    "market_sentiment": "å¸‚åœºæƒ…ç»ª",
    "hot_topics": "ç›¸å…³çƒ­ç‚¹",

    "search_performed": true/false,
    "data_sources": "æ•°æ®æ¥æºè¯´æ˜"
}
```

## è¯„åˆ†æ ‡å‡†

### å¼ºçƒˆä¹°å…¥ï¼ˆ80-100åˆ†ï¼‰ï¼š
- âœ… å¤šå¤´æ’åˆ—ï¼šMA5 > MA10 > MA20
- âœ… ä½ä¹–ç¦»ç‡ï¼š<2%ï¼Œæœ€ä½³ä¹°ç‚¹
- âœ… ç¼©é‡å›è°ƒæˆ–æ”¾é‡çªç ´
- âœ… ç­¹ç é›†ä¸­å¥åº·
- âœ… æ¶ˆæ¯é¢æœ‰åˆ©å¥½å‚¬åŒ–

### ä¹°å…¥ï¼ˆ60-79åˆ†ï¼‰ï¼š
- âœ… å¤šå¤´æ’åˆ—æˆ–å¼±åŠ¿å¤šå¤´
- âœ… ä¹–ç¦»ç‡ <5%
- âœ… é‡èƒ½æ­£å¸¸
- âšª å…è®¸ä¸€é¡¹æ¬¡è¦æ¡ä»¶ä¸æ»¡è¶³

### è§‚æœ›ï¼ˆ40-59åˆ†ï¼‰ï¼š
- âš ï¸ ä¹–ç¦»ç‡ >5%ï¼ˆè¿½é«˜é£é™©ï¼‰
- âš ï¸ å‡çº¿ç¼ ç»•è¶‹åŠ¿ä¸æ˜
- âš ï¸ æœ‰é£é™©äº‹ä»¶

### å–å‡º/å‡ä»“ï¼ˆ0-39åˆ†ï¼‰ï¼š
- âŒ ç©ºå¤´æ’åˆ—
- âŒ è·Œç ´MA20
- âŒ æ”¾é‡ä¸‹è·Œ
- âŒ é‡å¤§åˆ©ç©º

## å†³ç­–ä»ªè¡¨ç›˜æ ¸å¿ƒåŸåˆ™

1. **æ ¸å¿ƒç»“è®ºå…ˆè¡Œ**ï¼šä¸€å¥è¯è¯´æ¸…è¯¥ä¹°è¯¥å–
2. **åˆ†æŒä»“å»ºè®®**ï¼šç©ºä»“è€…å’ŒæŒä»“è€…ç»™ä¸åŒå»ºè®®
3. **ç²¾ç¡®ç‹™å‡»ç‚¹**ï¼šå¿…é¡»ç»™å‡ºå…·ä½“ä»·æ ¼ï¼Œä¸è¯´æ¨¡ç³Šçš„è¯
4. **æ£€æŸ¥æ¸…å•å¯è§†åŒ–**ï¼šç”¨ âœ…âš ï¸âŒ æ˜ç¡®æ˜¾ç¤ºæ¯é¡¹æ£€æŸ¥ç»“æœ
5. **é£é™©ä¼˜å…ˆçº§**ï¼šèˆ†æƒ…ä¸­çš„é£é™©ç‚¹è¦é†’ç›®æ ‡å‡º"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨

        ä¼˜å…ˆçº§ï¼šGemini > OpenAI å…¼å®¹ API

        Args:
            api_key: Gemini API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»é…ç½®è¯»å–ï¼‰
        """
        config = get_config()
        self._api_key = api_key or config.gemini_api_key
        self._model = None
        self._current_model_name = None  # å½“å‰ä½¿ç”¨çš„æ¨¡å‹åç§°
        self._using_fallback = False  # æ˜¯å¦æ­£åœ¨ä½¿ç”¨å¤‡é€‰æ¨¡å‹
        self._use_openai = False  # æ˜¯å¦ä½¿ç”¨ OpenAI å…¼å®¹ API
        self._openai_client = None  # OpenAI å®¢æˆ·ç«¯

        # æ£€æŸ¥ Gemini API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        gemini_key_valid = self._api_key and not self._api_key.startswith('your_') and len(self._api_key) > 10

        # ä¼˜å…ˆå°è¯•åˆå§‹åŒ– Gemini
        if gemini_key_valid:
            try:
                self._init_model()
            except Exception as e:
                logger.warning(f"Gemini åˆå§‹åŒ–å¤±è´¥: {e}ï¼Œå°è¯• OpenAI å…¼å®¹ API")
                self._init_openai_fallback()
        else:
            # Gemini Key æœªé…ç½®ï¼Œå°è¯• OpenAI
            logger.info("Gemini API Key æœªé…ç½®ï¼Œå°è¯•ä½¿ç”¨ OpenAI å…¼å®¹ API")
            self._init_openai_fallback()

        # ä¸¤è€…éƒ½æœªé…ç½®
        if not self._model and not self._openai_client:
            logger.warning("æœªé…ç½®ä»»ä½• AI API Keyï¼ŒAI åˆ†æåŠŸèƒ½å°†ä¸å¯ç”¨")

    def _init_openai_fallback(self) -> None:
        """
        åˆå§‹åŒ– OpenAI å…¼å®¹ API ä½œä¸ºå¤‡é€‰

        æ”¯æŒæ‰€æœ‰ OpenAI æ ¼å¼çš„ APIï¼ŒåŒ…æ‹¬ï¼š
        - OpenAI å®˜æ–¹
        - DeepSeek
        - é€šä¹‰åƒé—®
        - Moonshot ç­‰
        """
        config = get_config()

        # æ£€æŸ¥ OpenAI API Key æ˜¯å¦æœ‰æ•ˆï¼ˆè¿‡æ»¤å ä½ç¬¦ï¼‰
        openai_key_valid = (
            config.openai_api_key and
            not config.openai_api_key.startswith('your_') and
            len(config.openai_api_key) > 10
        )

        if not openai_key_valid:
            logger.debug("OpenAI å…¼å®¹ API æœªé…ç½®æˆ–é…ç½®æ— æ•ˆ")
            return

        # åˆ†ç¦» import å’Œå®¢æˆ·ç«¯åˆ›å»ºï¼Œä»¥ä¾¿æä¾›æ›´å‡†ç¡®çš„é”™è¯¯ä¿¡æ¯
        try:
            from openai import OpenAI
        except ImportError:
            logger.error("æœªå®‰è£… openai åº“ï¼Œè¯·è¿è¡Œ: pip install openai")
            return

        try:
            # base_url å¯é€‰ï¼Œä¸å¡«åˆ™ä½¿ç”¨ OpenAI å®˜æ–¹é»˜è®¤åœ°å€
            client_kwargs = {"api_key": config.openai_api_key}
            if config.openai_base_url and config.openai_base_url.startswith('http'):
                client_kwargs["base_url"] = config.openai_base_url

            self._openai_client = OpenAI(**client_kwargs)
            self._current_model_name = config.openai_model
            self._use_openai = True
            logger.info(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–æˆåŠŸ (base_url: {config.openai_base_url}, model: {config.openai_model})")
        except ImportError as e:
            # ä¾èµ–ç¼ºå¤±ï¼ˆå¦‚ socksioï¼‰
            if 'socksio' in str(e).lower() or 'socks' in str(e).lower():
                logger.error(f"OpenAI å®¢æˆ·ç«¯éœ€è¦ SOCKS ä»£ç†æ”¯æŒï¼Œè¯·è¿è¡Œ: pip install httpx[socks] æˆ– pip install socksio")
            else:
                logger.error(f"OpenAI ä¾èµ–ç¼ºå¤±: {e}")
        except Exception as e:
            error_msg = str(e).lower()
            if 'socks' in error_msg or 'socksio' in error_msg or 'proxy' in error_msg:
                logger.error(f"OpenAI ä»£ç†é…ç½®é”™è¯¯: {e}ï¼Œå¦‚ä½¿ç”¨ SOCKS ä»£ç†è¯·è¿è¡Œ: pip install httpx[socks]")
            else:
                logger.error(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–å¤±è´¥: {e}")

    def _init_model(self) -> None:
        """
        åˆå§‹åŒ– Gemini æ¨¡å‹

        é…ç½®ï¼š
        - ä½¿ç”¨ gemini-3-flash-preview æˆ– gemini-2.5-flash æ¨¡å‹
        - ä¸å¯ç”¨ Google Searchï¼ˆä½¿ç”¨å¤–éƒ¨ Tavily/SerpAPI æœç´¢ï¼‰
        """
        try:
            import google.generativeai as genai

            # é…ç½® API Key
            genai.configure(api_key=self._api_key)

            # ä»é…ç½®è·å–æ¨¡å‹åç§°
            config = get_config()
            model_name = config.gemini_model
            fallback_model = config.gemini_model_fallback

            # ä¸å†ä½¿ç”¨ Google Search Groundingï¼ˆå·²çŸ¥æœ‰å…¼å®¹æ€§é—®é¢˜ï¼‰
            # æ”¹ä¸ºä½¿ç”¨å¤–éƒ¨æœç´¢æœåŠ¡ï¼ˆTavily/SerpAPIï¼‰é¢„å…ˆè·å–æ–°é—»

            # å°è¯•åˆå§‹åŒ–ä¸»æ¨¡å‹
            try:
                self._model = genai.GenerativeModel(
                    model_name=model_name,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = model_name
                self._using_fallback = False
                logger.info(f"Gemini æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {model_name})")
            except Exception as model_error:
                # å°è¯•å¤‡é€‰æ¨¡å‹
                logger.warning(f"ä¸»æ¨¡å‹ {model_name} åˆå§‹åŒ–å¤±è´¥: {model_error}ï¼Œå°è¯•å¤‡é€‰æ¨¡å‹ {fallback_model}")
                self._model = genai.GenerativeModel(
                    model_name=fallback_model,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = fallback_model
                self._using_fallback = True
                logger.info(f"Gemini å¤‡é€‰æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {fallback_model})")

        except Exception as e:
            logger.error(f"Gemini æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            self._model = None

    def _switch_to_fallback_model(self) -> bool:
        """
        åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹

        Returns:
            æ˜¯å¦æˆåŠŸåˆ‡æ¢
        """
        try:
            import google.generativeai as genai
            config = get_config()
            fallback_model = config.gemini_model_fallback

            logger.warning(f"[LLM] åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹: {fallback_model}")
            self._model = genai.GenerativeModel(
                model_name=fallback_model,
                system_instruction=self.SYSTEM_PROMPT,
            )
            self._current_model_name = fallback_model
            self._using_fallback = True
            logger.info(f"[LLM] å¤‡é€‰æ¨¡å‹ {fallback_model} åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"[LLM] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥: {e}")
            return False

    def is_available(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self._model is not None or self._openai_client is not None

    def _call_openai_api(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ OpenAI å…¼å®¹ API

        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®

        Returns:
            å“åº”æ–‡æœ¬
        """
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay

        def _build_base_request_kwargs() -> dict:
            kwargs = {
                "model": self._current_model_name,
                "messages": [
                    {"role": "system", "content": self.SYSTEM_PROMPT},
                    {"role": "user", "content": prompt},
                ],
                "temperature": generation_config.get('temperature', config.openai_temperature),
            }
            return kwargs

        def _is_unsupported_param_error(error_message: str, param_name: str) -> bool:
            lower_msg = error_message.lower()
            return ('400' in lower_msg or "unsupported parameter" in lower_msg or "unsupported param" in lower_msg) and param_name in lower_msg

        if not hasattr(self, "_token_param_mode"):
            self._token_param_mode = {}

        max_output_tokens = generation_config.get('max_output_tokens', 8192)
        model_name = self._current_model_name
        mode = self._token_param_mode.get(model_name, "max_tokens")

        def _kwargs_with_mode(mode_value):
            kwargs = _build_base_request_kwargs()
            if mode_value is not None:
                kwargs[mode_value] = max_output_tokens
            return kwargs

        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))
                    delay = min(delay, 60)
                    logger.info(f"[OpenAI] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)

                try:
                    response = self._openai_client.chat.completions.create(**_kwargs_with_mode(mode))
                except Exception as e:
                    error_str = str(e)
                    if mode == "max_tokens" and _is_unsupported_param_error(error_str, "max_tokens"):
                        mode = "max_completion_tokens"
                        self._token_param_mode[model_name] = mode
                        response = self._openai_client.chat.completions.create(**_kwargs_with_mode(mode))
                    elif mode == "max_completion_tokens" and _is_unsupported_param_error(error_str, "max_completion_tokens"):
                        mode = None
                        self._token_param_mode[model_name] = mode
                        response = self._openai_client.chat.completions.create(**_kwargs_with_mode(mode))
                    else:
                        raise

                if response and response.choices and response.choices[0].message.content:
                    return response.choices[0].message.content
                else:
                    raise ValueError("OpenAI API è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                error_str = str(e)
                is_rate_limit = '429' in error_str or 'rate' in error_str.lower() or 'quota' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[OpenAI] API é™æµï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                else:
                    logger.warning(f"[OpenAI] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                
                if attempt == max_retries - 1:
                    raise
        
        raise Exception("OpenAI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _call_api_with_retry(self, prompt: str, generation_config: dict) -> str:
        """
        è°ƒç”¨ AI APIï¼Œå¸¦æœ‰é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢æœºåˆ¶
        
        ä¼˜å…ˆçº§ï¼šGemini > Gemini å¤‡é€‰æ¨¡å‹ > OpenAI å…¼å®¹ API
        
        å¤„ç† 429 é™æµé”™è¯¯ï¼š
        1. å…ˆæŒ‡æ•°é€€é¿é‡è¯•
        2. å¤šæ¬¡å¤±è´¥ååˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹
        3. Gemini å®Œå…¨å¤±è´¥åå°è¯• OpenAI
        
        Args:
            prompt: æç¤ºè¯
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            å“åº”æ–‡æœ¬
        """
        # å¦‚æœå·²ç»åœ¨ä½¿ç”¨ OpenAI æ¨¡å¼ï¼Œç›´æ¥è°ƒç”¨ OpenAI
        if self._use_openai:
            return self._call_openai_api(prompt, generation_config)
        
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        last_error = None
        tried_fallback = getattr(self, '_using_fallback', False)
        
        for attempt in range(max_retries):
            try:
                # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¯·æ±‚è¿‡å¿«è§¦å‘é™æµï¼‰
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))  # æŒ‡æ•°é€€é¿: 5, 10, 20, 40...
                    delay = min(delay, 60)  # æœ€å¤§60ç§’
                    logger.info(f"[Gemini] ç¬¬ {attempt + 1} æ¬¡é‡è¯•ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                response = self._model.generate_content(
                    prompt,
                    generation_config=generation_config,
                    request_options={"timeout": 120}
                )
                
                if response and response.text:
                    return response.text
                else:
                    raise ValueError("Gemini è¿”å›ç©ºå“åº”")
                    
            except Exception as e:
                last_error = e
                error_str = str(e)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 é™æµé”™è¯¯
                is_rate_limit = '429' in error_str or 'quota' in error_str.lower() or 'rate' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[Gemini] API é™æµ (429)ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
                    
                    # å¦‚æœå·²ç»é‡è¯•äº†ä¸€åŠæ¬¡æ•°ä¸”è¿˜æ²¡åˆ‡æ¢è¿‡å¤‡é€‰æ¨¡å‹ï¼Œå°è¯•åˆ‡æ¢
                    if attempt >= max_retries // 2 and not tried_fallback:
                        if self._switch_to_fallback_model():
                            tried_fallback = True
                            logger.info("[Gemini] å·²åˆ‡æ¢åˆ°å¤‡é€‰æ¨¡å‹ï¼Œç»§ç»­é‡è¯•")
                        else:
                            logger.warning("[Gemini] åˆ‡æ¢å¤‡é€‰æ¨¡å‹å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨å½“å‰æ¨¡å‹é‡è¯•")
                else:
                    # éé™æµé”™è¯¯ï¼Œè®°å½•å¹¶ç»§ç»­é‡è¯•
                    logger.warning(f"[Gemini] API è°ƒç”¨å¤±è´¥ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å°è¯•: {error_str[:100]}")
        
        # Gemini æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œå°è¯• OpenAI å…¼å®¹ API
        if self._openai_client:
            logger.warning("[Gemini] æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œåˆ‡æ¢åˆ° OpenAI å…¼å®¹ API")
            try:
                return self._call_openai_api(prompt, generation_config)
            except Exception as openai_error:
                logger.error(f"[OpenAI] å¤‡é€‰ API ä¹Ÿå¤±è´¥: {openai_error}")
                raise last_error or openai_error
        elif config.openai_api_key and config.openai_base_url:
            # å°è¯•æ‡’åŠ è½½åˆå§‹åŒ– OpenAI
            logger.warning("[Gemini] æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œå°è¯•åˆå§‹åŒ– OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
            if self._openai_client:
                try:
                    return self._call_openai_api(prompt, generation_config)
                except Exception as openai_error:
                    logger.error(f"[OpenAI] å¤‡é€‰ API ä¹Ÿå¤±è´¥: {openai_error}")
                    raise last_error or openai_error
        
        # æ‰€æœ‰æ–¹å¼éƒ½å¤±è´¥
        raise last_error or Exception("æ‰€æœ‰ AI API è°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def analyze(
        self, 
        context: Dict[str, Any],
        news_context: Optional[str] = None
    ) -> AnalysisResult:
        """
        åˆ†æå•åªè‚¡ç¥¨
        
        æµç¨‹ï¼š
        1. æ ¼å¼åŒ–è¾“å…¥æ•°æ®ï¼ˆæŠ€æœ¯é¢ + æ–°é—»ï¼‰
        2. è°ƒç”¨ Gemini APIï¼ˆå¸¦é‡è¯•å’Œæ¨¡å‹åˆ‡æ¢ï¼‰
        3. è§£æ JSON å“åº”
        4. è¿”å›ç»“æ„åŒ–ç»“æœ
        
        Args:
            context: ä» storage.get_analysis_context() è·å–çš„ä¸Šä¸‹æ–‡æ•°æ®
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            AnalysisResult å¯¹è±¡
        """
        code = context.get('code', 'Unknown')
        config = get_config()
        
        # è¯·æ±‚å‰å¢åŠ å»¶æ—¶ï¼ˆé˜²æ­¢è¿ç»­è¯·æ±‚è§¦å‘é™æµï¼‰
        request_delay = config.gemini_request_delay
        if request_delay > 0:
            logger.debug(f"[LLM] è¯·æ±‚å‰ç­‰å¾… {request_delay:.1f} ç§’...")
            time.sleep(request_delay)
        
        # ä¼˜å…ˆä»ä¸Šä¸‹æ–‡è·å–è‚¡ç¥¨åç§°ï¼ˆç”± main.py ä¼ å…¥ï¼‰
        name = context.get('stock_name')
        if not name or name.startswith('è‚¡ç¥¨'):
            # å¤‡é€‰ï¼šä» realtime ä¸­è·å–
            if 'realtime' in context and context['realtime'].get('name'):
                name = context['realtime']['name']
            else:
                # æœ€åä»æ˜ å°„è¡¨è·å–
                name = STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
        
        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤ç»“æœ
        if not self.is_available():
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡è¡',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary='AI åˆ†æåŠŸèƒ½æœªå¯ç”¨ï¼ˆæœªé…ç½® API Keyï¼‰',
                risk_warning='è¯·é…ç½® Gemini API Key åé‡è¯•',
                success=False,
                error_message='Gemini API Key æœªé…ç½®',
            )
        
        try:
            # æ ¼å¼åŒ–è¾“å…¥ï¼ˆåŒ…å«æŠ€æœ¯é¢æ•°æ®å’Œæ–°é—»ï¼‰
            prompt = self._format_prompt(context, name, news_context)
            
            # è·å–æ¨¡å‹åç§°
            model_name = getattr(self, '_current_model_name', None)
            if not model_name:
                model_name = getattr(self._model, '_model_name', 'unknown')
                if hasattr(self._model, 'model_name'):
                    model_name = self._model.model_name
            
            logger.info(f"========== AI åˆ†æ {name}({code}) ==========")
            logger.info(f"[LLMé…ç½®] æ¨¡å‹: {model_name}")
            logger.info(f"[LLMé…ç½®] Prompt é•¿åº¦: {len(prompt)} å­—ç¬¦")
            logger.info(f"[LLMé…ç½®] æ˜¯å¦åŒ…å«æ–°é—»: {'æ˜¯' if news_context else 'å¦'}")
            
            # è®°å½•å®Œæ•´ prompt åˆ°æ—¥å¿—ï¼ˆINFOçº§åˆ«è®°å½•æ‘˜è¦ï¼ŒDEBUGè®°å½•å®Œæ•´ï¼‰
            prompt_preview = prompt[:500] + "..." if len(prompt) > 500 else prompt
            logger.info(f"[LLM Prompt é¢„è§ˆ]\n{prompt_preview}")
            logger.debug(f"=== å®Œæ•´ Prompt ({len(prompt)}å­—ç¬¦) ===\n{prompt}\n=== End Prompt ===")

            # è®¾ç½®ç”Ÿæˆé…ç½®ï¼ˆä»é…ç½®æ–‡ä»¶è¯»å–æ¸©åº¦å‚æ•°ï¼‰
            config = get_config()
            generation_config = {
                "temperature": config.gemini_temperature,
                "max_output_tokens": 8192,
            }

            # æ ¹æ®å®é™…ä½¿ç”¨çš„ API æ˜¾ç¤ºæ—¥å¿—
            api_provider = "OpenAI" if self._use_openai else "Gemini"
            logger.info(f"[LLMè°ƒç”¨] å¼€å§‹è°ƒç”¨ {api_provider} API...")
            
            # ä½¿ç”¨å¸¦é‡è¯•çš„ API è°ƒç”¨
            start_time = time.time()
            response_text = self._call_api_with_retry(prompt, generation_config)
            elapsed = time.time() - start_time

            # è®°å½•å“åº”ä¿¡æ¯
            logger.info(f"[LLMè¿”å›] {api_provider} API å“åº”æˆåŠŸ, è€—æ—¶ {elapsed:.2f}s, å“åº”é•¿åº¦ {len(response_text)} å­—ç¬¦")
            
            # è®°å½•å“åº”é¢„è§ˆï¼ˆINFOçº§åˆ«ï¼‰å’Œå®Œæ•´å“åº”ï¼ˆDEBUGçº§åˆ«ï¼‰
            response_preview = response_text[:300] + "..." if len(response_text) > 300 else response_text
            logger.info(f"[LLMè¿”å› é¢„è§ˆ]\n{response_preview}")
            logger.debug(f"=== {api_provider} å®Œæ•´å“åº” ({len(response_text)}å­—ç¬¦) ===\n{response_text}\n=== End Response ===")
            
            # è§£æå“åº”
            result = self._parse_response(response_text, code, name)
            result.raw_response = response_text
            result.search_performed = bool(news_context)
            result.market_snapshot = self._build_market_snapshot(context)

            logger.info(f"[LLMè§£æ] {name}({code}) åˆ†æå®Œæˆ: {result.trend_prediction}, è¯„åˆ† {result.sentiment_score}")
            
            return result
            
        except Exception as e:
            logger.error(f"AI åˆ†æ {name}({code}) å¤±è´¥: {e}")
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡è¡',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary=f'åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)[:100]}',
                risk_warning='åˆ†æå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•æˆ–æ‰‹åŠ¨åˆ†æ',
                success=False,
                error_message=str(e),
            )
    
    def _format_prompt(
        self, 
        context: Dict[str, Any], 
        name: str,
        news_context: Optional[str] = None
    ) -> str:
        """
        æ ¼å¼åŒ–åˆ†ææç¤ºè¯ï¼ˆå†³ç­–ä»ªè¡¨ç›˜ v2.0ï¼‰
        
        åŒ…å«ï¼šæŠ€æœ¯æŒ‡æ ‡ã€å®æ—¶è¡Œæƒ…ï¼ˆé‡æ¯”/æ¢æ‰‹ç‡ï¼‰ã€ç­¹ç åˆ†å¸ƒã€è¶‹åŠ¿åˆ†æã€æ–°é—»
        
        Args:
            context: æŠ€æœ¯é¢æ•°æ®ä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å¢å¼ºæ•°æ®ï¼‰
            name: è‚¡ç¥¨åç§°ï¼ˆé»˜è®¤å€¼ï¼Œå¯èƒ½è¢«ä¸Šä¸‹æ–‡è¦†ç›–ï¼‰
            news_context: é¢„å…ˆæœç´¢çš„æ–°é—»å†…å®¹
        """
        code = context.get('code', 'Unknown')
        
        # ä¼˜å…ˆä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­çš„è‚¡ç¥¨åç§°ï¼ˆä» realtime_quote è·å–ï¼‰
        stock_name = context.get('stock_name', name)
        if not stock_name or stock_name == f'è‚¡ç¥¨{code}':
            stock_name = STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
            
        today = context.get('today', {})
        
        # ========== æ„å»ºå†³ç­–ä»ªè¡¨ç›˜æ ¼å¼çš„è¾“å…¥ ==========
        prompt = f"""# å†³ç­–ä»ªè¡¨ç›˜åˆ†æè¯·æ±‚

## ğŸ“Š è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
| é¡¹ç›® | æ•°æ® |
|------|------|
| è‚¡ç¥¨ä»£ç  | **{code}** |
| è‚¡ç¥¨åç§° | **{stock_name}** |
| åˆ†ææ—¥æœŸ | {context.get('date', 'æœªçŸ¥')} |

---

## ğŸ“ˆ æŠ€æœ¯é¢æ•°æ®

### ä»Šæ—¥è¡Œæƒ…
| æŒ‡æ ‡ | æ•°å€¼ |
|------|------|
| æ”¶ç›˜ä»· | {today.get('close', 'N/A')} å…ƒ |
| å¼€ç›˜ä»· | {today.get('open', 'N/A')} å…ƒ |
| æœ€é«˜ä»· | {today.get('high', 'N/A')} å…ƒ |
| æœ€ä½ä»· | {today.get('low', 'N/A')} å…ƒ |
| æ¶¨è·Œå¹… | {today.get('pct_chg', 'N/A')}% |
| æˆäº¤é‡ | {self._format_volume(today.get('volume'))} |
| æˆäº¤é¢ | {self._format_amount(today.get('amount'))} |

### å‡çº¿ç³»ç»Ÿï¼ˆå…³é”®åˆ¤æ–­æŒ‡æ ‡ï¼‰
| å‡çº¿ | æ•°å€¼ | è¯´æ˜ |
|------|------|------|
| MA5 | {today.get('ma5', 'N/A')} | çŸ­æœŸè¶‹åŠ¿çº¿ |
| MA10 | {today.get('ma10', 'N/A')} | ä¸­çŸ­æœŸè¶‹åŠ¿çº¿ |
| MA20 | {today.get('ma20', 'N/A')} | ä¸­æœŸè¶‹åŠ¿çº¿ |
| å‡çº¿å½¢æ€ | {context.get('ma_status', 'æœªçŸ¥')} | å¤šå¤´/ç©ºå¤´/ç¼ ç»• |
"""
        
        # æ·»åŠ å®æ—¶è¡Œæƒ…æ•°æ®ï¼ˆé‡æ¯”ã€æ¢æ‰‹ç‡ç­‰ï¼‰
        if 'realtime' in context:
            rt = context['realtime']
            prompt += f"""
### å®æ—¶è¡Œæƒ…å¢å¼ºæ•°æ®
| æŒ‡æ ‡ | æ•°å€¼ | è§£è¯» |
|------|------|------|
| å½“å‰ä»·æ ¼ | {rt.get('price', 'N/A')} å…ƒ | |
| **é‡æ¯”** | **{rt.get('volume_ratio', 'N/A')}** | {rt.get('volume_ratio_desc', '')} |
| **æ¢æ‰‹ç‡** | **{rt.get('turnover_rate', 'N/A')}%** | |
| å¸‚ç›ˆç‡(åŠ¨æ€) | {rt.get('pe_ratio', 'N/A')} | |
| å¸‚å‡€ç‡ | {rt.get('pb_ratio', 'N/A')} | |
| æ€»å¸‚å€¼ | {self._format_amount(rt.get('total_mv'))} | |
| æµé€šå¸‚å€¼ | {self._format_amount(rt.get('circ_mv'))} | |
| 60æ—¥æ¶¨è·Œå¹… | {rt.get('change_60d', 'N/A')}% | ä¸­æœŸè¡¨ç° |
"""
        
        # æ·»åŠ ç­¹ç åˆ†å¸ƒæ•°æ®
        if 'chip' in context:
            chip = context['chip']
            profit_ratio = chip.get('profit_ratio', 0)
            prompt += f"""
### ç­¹ç åˆ†å¸ƒæ•°æ®ï¼ˆæ•ˆç‡æŒ‡æ ‡ï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | å¥åº·æ ‡å‡† |
|------|------|----------|
| **è·åˆ©æ¯”ä¾‹** | **{profit_ratio:.1%}** | 70-90%æ—¶è­¦æƒ• |
| å¹³å‡æˆæœ¬ | {chip.get('avg_cost', 'N/A')} å…ƒ | ç°ä»·åº”é«˜äº5-15% |
| 90%ç­¹ç é›†ä¸­åº¦ | {chip.get('concentration_90', 0):.2%} | <15%ä¸ºé›†ä¸­ |
| 70%ç­¹ç é›†ä¸­åº¦ | {chip.get('concentration_70', 0):.2%} | |
| ç­¹ç çŠ¶æ€ | {chip.get('chip_status', 'æœªçŸ¥')} | |
"""
        
        # æ·»åŠ è¶‹åŠ¿åˆ†æç»“æœï¼ˆåŸºäºäº¤æ˜“ç†å¿µçš„é¢„åˆ¤ï¼‰
        if 'trend_analysis' in context:
            trend = context['trend_analysis']
            bias_warning = "ğŸš¨ è¶…è¿‡5%ï¼Œä¸¥ç¦è¿½é«˜ï¼" if trend.get('bias_ma5', 0) > 5 else "âœ… å®‰å…¨èŒƒå›´"
            prompt += f"""
### è¶‹åŠ¿åˆ†æé¢„åˆ¤ï¼ˆåŸºäºäº¤æ˜“ç†å¿µï¼‰
| æŒ‡æ ‡ | æ•°å€¼ | åˆ¤å®š |
|------|------|------|
| è¶‹åŠ¿çŠ¶æ€ | {trend.get('trend_status', 'æœªçŸ¥')} | |
| å‡çº¿æ’åˆ— | {trend.get('ma_alignment', 'æœªçŸ¥')} | MA5>MA10>MA20ä¸ºå¤šå¤´ |
| è¶‹åŠ¿å¼ºåº¦ | {trend.get('trend_strength', 0)}/100 | |
| **ä¹–ç¦»ç‡(MA5)** | **{trend.get('bias_ma5', 0):+.2f}%** | {bias_warning} |
| ä¹–ç¦»ç‡(MA10) | {trend.get('bias_ma10', 0):+.2f}% | |
| é‡èƒ½çŠ¶æ€ | {trend.get('volume_status', 'æœªçŸ¥')} | {trend.get('volume_trend', '')} |
| ç³»ç»Ÿä¿¡å· | {trend.get('buy_signal', 'æœªçŸ¥')} | |
| ç³»ç»Ÿè¯„åˆ† | {trend.get('signal_score', 0)}/100 | |

#### ç³»ç»Ÿåˆ†æç†ç”±
**ä¹°å…¥ç†ç”±**ï¼š
{chr(10).join('- ' + r for r in trend.get('signal_reasons', ['æ— '])) if trend.get('signal_reasons') else '- æ— '}

**é£é™©å› ç´ **ï¼š
{chr(10).join('- ' + r for r in trend.get('risk_factors', ['æ— '])) if trend.get('risk_factors') else '- æ— '}
"""
        
        # æ·»åŠ æ˜¨æ—¥å¯¹æ¯”æ•°æ®
        if 'yesterday' in context:
            volume_change = context.get('volume_change_ratio', 'N/A')
            prompt += f"""
### é‡ä»·å˜åŒ–
- æˆäº¤é‡è¾ƒæ˜¨æ—¥å˜åŒ–ï¼š{volume_change}å€
- ä»·æ ¼è¾ƒæ˜¨æ—¥å˜åŒ–ï¼š{context.get('price_change_ratio', 'N/A')}%
"""
        
        # æ·»åŠ æ–°é—»æœç´¢ç»“æœï¼ˆé‡ç‚¹åŒºåŸŸï¼‰
        prompt += """
---

## ğŸ“° èˆ†æƒ…æƒ…æŠ¥
"""
        if news_context:
            prompt += f"""
ä»¥ä¸‹æ˜¯ **{stock_name}({code})** è¿‘7æ—¥çš„æ–°é—»æœç´¢ç»“æœï¼Œè¯·é‡ç‚¹æå–ï¼š
1. ğŸš¨ **é£é™©è­¦æŠ¥**ï¼šå‡æŒã€å¤„ç½šã€åˆ©ç©º
2. ğŸ¯ **åˆ©å¥½å‚¬åŒ–**ï¼šä¸šç»©ã€åˆåŒã€æ”¿ç­–
3. ğŸ“Š **ä¸šç»©é¢„æœŸ**ï¼šå¹´æŠ¥é¢„å‘Šã€ä¸šç»©å¿«æŠ¥

```
{news_context}
```
"""
        else:
            prompt += """
æœªæœç´¢åˆ°è¯¥è‚¡ç¥¨è¿‘æœŸçš„ç›¸å…³æ–°é—»ã€‚è¯·ä¸»è¦ä¾æ®æŠ€æœ¯é¢æ•°æ®è¿›è¡Œåˆ†æã€‚
"""

        # æ³¨å…¥ç¼ºå¤±æ•°æ®è­¦å‘Š
        if context.get('data_missing'):
            prompt += """
âš ï¸ **æ•°æ®ç¼ºå¤±è­¦å‘Š**
ç”±äºæ¥å£é™åˆ¶ï¼Œå½“å‰æ— æ³•è·å–å®Œæ•´çš„å®æ—¶è¡Œæƒ…å’ŒæŠ€æœ¯æŒ‡æ ‡æ•°æ®ã€‚
è¯· **å¿½ç•¥ä¸Šè¿°è¡¨æ ¼ä¸­çš„ N/A æ•°æ®**ï¼Œé‡ç‚¹ä¾æ® **ã€ğŸ“° èˆ†æƒ…æƒ…æŠ¥ã€‘** ä¸­çš„æ–°é—»è¿›è¡ŒåŸºæœ¬é¢å’Œæƒ…ç»ªé¢åˆ†æã€‚
åœ¨å›ç­”æŠ€æœ¯é¢é—®é¢˜ï¼ˆå¦‚å‡çº¿ã€ä¹–ç¦»ç‡ï¼‰æ—¶ï¼Œè¯·ç›´æ¥è¯´æ˜â€œæ•°æ®ç¼ºå¤±ï¼Œæ— æ³•åˆ¤æ–­â€ï¼Œ**ä¸¥ç¦ç¼–é€ æ•°æ®**ã€‚
"""

        # æ˜ç¡®çš„è¾“å‡ºè¦æ±‚
        prompt += f"""
---

## âœ… åˆ†æä»»åŠ¡

è¯·ä¸º **{stock_name}({code})** ç”Ÿæˆã€å†³ç­–ä»ªè¡¨ç›˜ã€‘ï¼Œä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¾“å‡ºã€‚

### âš ï¸ é‡è¦ï¼šè‚¡ç¥¨åç§°ç¡®è®¤
å¦‚æœä¸Šæ–¹æ˜¾ç¤ºçš„è‚¡ç¥¨åç§°ä¸º"è‚¡ç¥¨{code}"æˆ–ä¸æ­£ç¡®ï¼Œè¯·åœ¨åˆ†æå¼€å¤´**æ˜ç¡®è¾“å‡ºè¯¥è‚¡ç¥¨çš„æ­£ç¡®ä¸­æ–‡å…¨ç§°**ã€‚

### é‡ç‚¹å…³æ³¨ï¼ˆå¿…é¡»æ˜ç¡®å›ç­”ï¼‰ï¼š
1. â“ æ˜¯å¦æ»¡è¶³ MA5>MA10>MA20 å¤šå¤´æ’åˆ—ï¼Ÿ
2. â“ å½“å‰ä¹–ç¦»ç‡æ˜¯å¦åœ¨å®‰å…¨èŒƒå›´å†…ï¼ˆ<5%ï¼‰ï¼Ÿâ€”â€” è¶…è¿‡5%å¿…é¡»æ ‡æ³¨"ä¸¥ç¦è¿½é«˜"
3. â“ é‡èƒ½æ˜¯å¦é…åˆï¼ˆç¼©é‡å›è°ƒ/æ”¾é‡çªç ´ï¼‰ï¼Ÿ
4. â“ ç­¹ç ç»“æ„æ˜¯å¦å¥åº·ï¼Ÿ
5. â“ æ¶ˆæ¯é¢æœ‰æ— é‡å¤§åˆ©ç©ºï¼Ÿï¼ˆå‡æŒã€å¤„ç½šã€ä¸šç»©å˜è„¸ç­‰ï¼‰

### å†³ç­–ä»ªè¡¨ç›˜è¦æ±‚ï¼š
- **è‚¡ç¥¨åç§°**ï¼šå¿…é¡»è¾“å‡ºæ­£ç¡®çš„ä¸­æ–‡å…¨ç§°ï¼ˆå¦‚"è´µå·èŒ…å°"è€Œé"è‚¡ç¥¨600519"ï¼‰
- **æ ¸å¿ƒç»“è®º**ï¼šä¸€å¥è¯è¯´æ¸…è¯¥ä¹°/è¯¥å–/è¯¥ç­‰
- **æŒä»“åˆ†ç±»å»ºè®®**ï¼šç©ºä»“è€…æ€ä¹ˆåš vs æŒä»“è€…æ€ä¹ˆåš
- **å…·ä½“ç‹™å‡»ç‚¹ä½**ï¼šä¹°å…¥ä»·ã€æ­¢æŸä»·ã€ç›®æ ‡ä»·ï¼ˆç²¾ç¡®åˆ°åˆ†ï¼‰
- **æ£€æŸ¥æ¸…å•**ï¼šæ¯é¡¹ç”¨ âœ…/âš ï¸/âŒ æ ‡è®°

è¯·è¾“å‡ºå®Œæ•´çš„ JSON æ ¼å¼å†³ç­–ä»ªè¡¨ç›˜ã€‚"""
        
        return prompt
    
    def _format_volume(self, volume: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é‡æ˜¾ç¤º"""
        if volume is None:
            return 'N/A'
        if volume >= 1e8:
            return f"{volume / 1e8:.2f} äº¿è‚¡"
        elif volume >= 1e4:
            return f"{volume / 1e4:.2f} ä¸‡è‚¡"
        else:
            return f"{volume:.0f} è‚¡"
    
    def _format_amount(self, amount: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é¢æ˜¾ç¤º"""
        if amount is None:
            return 'N/A'
        if amount >= 1e8:
            return f"{amount / 1e8:.2f} äº¿å…ƒ"
        elif amount >= 1e4:
            return f"{amount / 1e4:.2f} ä¸‡å…ƒ"
        else:
            return f"{amount:.0f} å…ƒ"

    def _format_percent(self, value: Optional[float]) -> str:
        """æ ¼å¼åŒ–ç™¾åˆ†æ¯”æ˜¾ç¤º"""
        if value is None:
            return 'N/A'
        try:
            return f"{float(value):.2f}%"
        except (TypeError, ValueError):
            return 'N/A'

    def _format_price(self, value: Optional[float]) -> str:
        """æ ¼å¼åŒ–ä»·æ ¼æ˜¾ç¤º"""
        if value is None:
            return 'N/A'
        try:
            return f"{float(value):.2f}"
        except (TypeError, ValueError):
            return 'N/A'

    def _build_market_snapshot(self, context: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºå½“æ—¥è¡Œæƒ…å¿«ç…§ï¼ˆå±•ç¤ºç”¨ï¼‰"""
        today = context.get('today', {}) or {}
        realtime = context.get('realtime', {}) or {}
        yesterday = context.get('yesterday', {}) or {}

        prev_close = yesterday.get('close')
        close = today.get('close')
        high = today.get('high')
        low = today.get('low')

        amplitude = None
        change_amount = None
        if prev_close not in (None, 0) and high is not None and low is not None:
            try:
                amplitude = (float(high) - float(low)) / float(prev_close) * 100
            except (TypeError, ValueError, ZeroDivisionError):
                amplitude = None
        if prev_close is not None and close is not None:
            try:
                change_amount = float(close) - float(prev_close)
            except (TypeError, ValueError):
                change_amount = None

        snapshot = {
            "date": context.get('date', 'æœªçŸ¥'),
            "close": self._format_price(close),
            "open": self._format_price(today.get('open')),
            "high": self._format_price(high),
            "low": self._format_price(low),
            "prev_close": self._format_price(prev_close),
            "pct_chg": self._format_percent(today.get('pct_chg')),
            "change_amount": self._format_price(change_amount),
            "amplitude": self._format_percent(amplitude),
            "volume": self._format_volume(today.get('volume')),
            "amount": self._format_amount(today.get('amount')),
        }

        if realtime:
            snapshot.update({
                "price": self._format_price(realtime.get('price')),
                "volume_ratio": realtime.get('volume_ratio', 'N/A'),
                "turnover_rate": self._format_percent(realtime.get('turnover_rate')),
                "source": getattr(realtime.get('source'), 'value', realtime.get('source', 'N/A')),
            })

        return snapshot

    def _parse_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """
        è§£æ Gemini å“åº”ï¼ˆå†³ç­–ä»ªè¡¨ç›˜ç‰ˆï¼‰
        
        å°è¯•ä»å“åº”ä¸­æå– JSON æ ¼å¼çš„åˆ†æç»“æœï¼ŒåŒ…å« dashboard å­—æ®µ
        å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•æ™ºèƒ½æå–æˆ–è¿”å›é»˜è®¤ç»“æœ
        """
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼šç§»é™¤ markdown ä»£ç å—æ ‡è®°
            cleaned_text = response_text
            if '```json' in cleaned_text:
                cleaned_text = cleaned_text.replace('```json', '').replace('```', '')
            elif '```' in cleaned_text:
                cleaned_text = cleaned_text.replace('```', '')
            
            # å°è¯•æ‰¾åˆ° JSON å†…å®¹
            json_start = cleaned_text.find('{')
            json_end = cleaned_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = cleaned_text[json_start:json_end]
                
                # å°è¯•ä¿®å¤å¸¸è§çš„ JSON é—®é¢˜
                json_str = self._fix_json_string(json_str)
                
                data = json.loads(json_str)
                
                # æå– dashboard æ•°æ®
                dashboard = data.get('dashboard', None)

                # ä¼˜å…ˆä½¿ç”¨ AI è¿”å›çš„è‚¡ç¥¨åç§°ï¼ˆå¦‚æœåŸåç§°æ— æ•ˆæˆ–åŒ…å«ä»£ç ï¼‰
                ai_stock_name = data.get('stock_name')
                if ai_stock_name and (name.startswith('è‚¡ç¥¨') or name == code or 'Unknown' in name):
                    name = ai_stock_name

                # è§£ææ‰€æœ‰å­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼é˜²æ­¢ç¼ºå¤±
                # è§£æ decision_typeï¼Œå¦‚æœæ²¡æœ‰åˆ™æ ¹æ® operation_advice æ¨æ–­
                decision_type = data.get('decision_type', '')
                if not decision_type:
                    op = data.get('operation_advice', 'æŒæœ‰')
                    if op in ['ä¹°å…¥', 'åŠ ä»“', 'å¼ºçƒˆä¹°å…¥']:
                        decision_type = 'buy'
                    elif op in ['å–å‡º', 'å‡ä»“', 'å¼ºçƒˆå–å‡º']:
                        decision_type = 'sell'
                    else:
                        decision_type = 'hold'
                
                return AnalysisResult(
                    code=code,
                    name=name,
                    # æ ¸å¿ƒæŒ‡æ ‡
                    sentiment_score=int(data.get('sentiment_score', 50)),
                    trend_prediction=data.get('trend_prediction', 'éœ‡è¡'),
                    operation_advice=data.get('operation_advice', 'æŒæœ‰'),
                    decision_type=decision_type,
                    confidence_level=data.get('confidence_level', 'ä¸­'),
                    # å†³ç­–ä»ªè¡¨ç›˜
                    dashboard=dashboard,
                    # èµ°åŠ¿åˆ†æ
                    trend_analysis=data.get('trend_analysis', ''),
                    short_term_outlook=data.get('short_term_outlook', ''),
                    medium_term_outlook=data.get('medium_term_outlook', ''),
                    # æŠ€æœ¯é¢
                    technical_analysis=data.get('technical_analysis', ''),
                    ma_analysis=data.get('ma_analysis', ''),
                    volume_analysis=data.get('volume_analysis', ''),
                    pattern_analysis=data.get('pattern_analysis', ''),
                    # åŸºæœ¬é¢
                    fundamental_analysis=data.get('fundamental_analysis', ''),
                    sector_position=data.get('sector_position', ''),
                    company_highlights=data.get('company_highlights', ''),
                    # æƒ…ç»ªé¢/æ¶ˆæ¯é¢
                    news_summary=data.get('news_summary', ''),
                    market_sentiment=data.get('market_sentiment', ''),
                    hot_topics=data.get('hot_topics', ''),
                    # ç»¼åˆ
                    analysis_summary=data.get('analysis_summary', 'åˆ†æå®Œæˆ'),
                    key_points=data.get('key_points', ''),
                    risk_warning=data.get('risk_warning', ''),
                    buy_reason=data.get('buy_reason', ''),
                    # å…ƒæ•°æ®
                    search_performed=data.get('search_performed', False),
                    data_sources=data.get('data_sources', 'æŠ€æœ¯é¢æ•°æ®'),
                    success=True,
                )
            else:
                # æ²¡æœ‰æ‰¾åˆ° JSONï¼Œå°è¯•ä»çº¯æ–‡æœ¬ä¸­æå–ä¿¡æ¯
                logger.warning(f"æ— æ³•ä»å“åº”ä¸­æå– JSONï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬åˆ†æ")
                return self._parse_text_response(response_text, code, name)
                
        except json.JSONDecodeError as e:
            logger.warning(f"JSON è§£æå¤±è´¥: {e}ï¼Œå°è¯•ä»æ–‡æœ¬æå–")
            return self._parse_text_response(response_text, code, name)
    
    def _fix_json_string(self, json_str: str) -> str:
        """ä¿®å¤å¸¸è§çš„ JSON æ ¼å¼é—®é¢˜"""
        import re
        
        # ç§»é™¤æ³¨é‡Š
        json_str = re.sub(r'//.*?\n', '\n', json_str)
        json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
        
        # ä¿®å¤å°¾éšé€—å·
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # ç¡®ä¿å¸ƒå°”å€¼æ˜¯å°å†™
        json_str = json_str.replace('True', 'true').replace('False', 'false')
        
        # fix by json-repair
        json_str = repair_json(json_str)
        
        return json_str
    
    def _parse_text_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """ä»çº¯æ–‡æœ¬å“åº”ä¸­å°½å¯èƒ½æå–åˆ†æä¿¡æ¯"""
        # å°è¯•è¯†åˆ«å…³é”®è¯æ¥åˆ¤æ–­æƒ…ç»ª
        sentiment_score = 50
        trend = 'éœ‡è¡'
        advice = 'æŒæœ‰'
        
        text_lower = response_text.lower()
        
        # ç®€å•çš„æƒ…ç»ªè¯†åˆ«
        positive_keywords = ['çœ‹å¤š', 'ä¹°å…¥', 'ä¸Šæ¶¨', 'çªç ´', 'å¼ºåŠ¿', 'åˆ©å¥½', 'åŠ ä»“', 'bullish', 'buy']
        negative_keywords = ['çœ‹ç©º', 'å–å‡º', 'ä¸‹è·Œ', 'è·Œç ´', 'å¼±åŠ¿', 'åˆ©ç©º', 'å‡ä»“', 'bearish', 'sell']
        
        positive_count = sum(1 for kw in positive_keywords if kw in text_lower)
        negative_count = sum(1 for kw in negative_keywords if kw in text_lower)
        
        if positive_count > negative_count + 1:
            sentiment_score = 65
            trend = 'çœ‹å¤š'
            advice = 'ä¹°å…¥'
            decision_type = 'buy'
        elif negative_count > positive_count + 1:
            sentiment_score = 35
            trend = 'çœ‹ç©º'
            advice = 'å–å‡º'
            decision_type = 'sell'
        else:
            decision_type = 'hold'
        
        # æˆªå–å‰500å­—ç¬¦ä½œä¸ºæ‘˜è¦
        summary = response_text[:500] if response_text else 'æ— åˆ†æç»“æœ'
        
        return AnalysisResult(
            code=code,
            name=name,
            sentiment_score=sentiment_score,
            trend_prediction=trend,
            operation_advice=advice,
            decision_type=decision_type,
            confidence_level='ä½',
            analysis_summary=summary,
            key_points='JSONè§£æå¤±è´¥ï¼Œä»…ä¾›å‚è€ƒ',
            risk_warning='åˆ†æç»“æœå¯èƒ½ä¸å‡†ç¡®ï¼Œå»ºè®®ç»“åˆå…¶ä»–ä¿¡æ¯åˆ¤æ–­',
            raw_response=response_text,
            success=True,
        )
    
    def batch_analyze(
        self, 
        contexts: List[Dict[str, Any]],
        delay_between: float = 2.0
    ) -> List[AnalysisResult]:
        """
        æ‰¹é‡åˆ†æå¤šåªè‚¡ç¥¨
        
        æ³¨æ„ï¼šä¸ºé¿å… API é€Ÿç‡é™åˆ¶ï¼Œæ¯æ¬¡åˆ†æä¹‹é—´ä¼šæœ‰å»¶è¿Ÿ
        
        Args:
            contexts: ä¸Šä¸‹æ–‡æ•°æ®åˆ—è¡¨
            delay_between: æ¯æ¬¡åˆ†æä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
            
        Returns:
            AnalysisResult åˆ—è¡¨
        """
        results = []
        
        for i, context in enumerate(contexts):
            if i > 0:
                logger.debug(f"ç­‰å¾… {delay_between} ç§’åç»§ç»­...")
                time.sleep(delay_between)
            
            result = self.analyze(context)
            results.append(result)
        
        return results


# ä¾¿æ·å‡½æ•°
def get_analyzer() -> GeminiAnalyzer:
    """è·å– Gemini åˆ†æå™¨å®ä¾‹"""
    return GeminiAnalyzer()


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.DEBUG)
    
    # æ¨¡æ‹Ÿä¸Šä¸‹æ–‡æ•°æ®
    test_context = {
        'code': '600519',
        'date': '2026-01-09',
        'today': {
            'open': 1800.0,
            'high': 1850.0,
            'low': 1780.0,
            'close': 1820.0,
            'volume': 10000000,
            'amount': 18200000000,
            'pct_chg': 1.5,
            'ma5': 1810.0,
            'ma10': 1800.0,
            'ma20': 1790.0,
            'volume_ratio': 1.2,
        },
        'ma_status': 'å¤šå¤´æ’åˆ— ğŸ“ˆ',
        'volume_change_ratio': 1.3,
        'price_change_ratio': 1.5,
    }
    
    analyzer = GeminiAnalyzer()
    
    if analyzer.is_available():
        print("=== AI åˆ†ææµ‹è¯• ===")
        result = analyzer.analyze(test_context)
        print(f"åˆ†æç»“æœ: {result.to_dict()}")
    else:
        print("Gemini API æœªé…ç½®ï¼Œè·³è¿‡æµ‹è¯•")
